{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c61458f-4af9-4890-9c02-70d2de623e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761b776e-5e70-4715-8b4e-91f4966c9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"json-read-write\").config(\"spark.driver.memory\",\"40g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3b5185-8a09-45d3-a37e-a2b6441f40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark.read.json(\"C:/Users/bibhusha.ojha_genese/Desktop/SparkSQL/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7e52a8-00ed-4683-9660-8ffd3840c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using DDL type to define schema\n",
    "df_schema = \"id INT , name STRING, age INT , city STRING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478d67a7-9629-4da4-ae43-b74b7cfe829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    ".schema(df_schema) \\\n",
    ".json(\"C:/Users/bibhusha.ojha_genese/Desktop/SparkSQL/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd5a014-6692-4657-a13a-d39b1f81f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd2ffc0-2fa7-4b1b-9758-ab925ba51c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted column(s)\n",
    "dropped_df = df.drop(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421ab243-9b6c-49de-a537-3938b7aab732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5659ad8-83ce-42d4-8395-d68ad7c04d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to drop\n",
    "from pyspark.sql.functions import col\n",
    "dropped_df = df.drop(col(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662c423f-47ff-496f-b851-c9fffbb8c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "#rename columns and add a new column\n",
    "final_df = dropped_df.withColumnRenamed(\"id\", \"serial_no\") \\\n",
    ".withColumn(\"ingestion_date\", current_timestamp()) #add new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd96c3e3-bd8f-428a-99ee-e123b76910ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------------+--------------------+\n",
      "|serial_no|          name|         city|      ingestion_date|\n",
      "+---------+--------------+-------------+--------------------+\n",
      "|     NULL|          NULL|         NULL|2024-01-24 10:40:...|\n",
      "|        1|      John Doe|     New York|2024-01-24 10:40:...|\n",
      "|        2|    Jane Smith|  Los Angeles|2024-01-24 10:40:...|\n",
      "|        3|Robert Johnson|      Chicago|2024-01-24 10:40:...|\n",
      "|        4|   Emily Davis|San Francisco|2024-01-24 10:40:...|\n",
      "+---------+--------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc678444-dd51-47b5-bf25-d6058978b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------------+-------------------------+\n",
      "|serial_no|name          |city         |ingestion_date           |\n",
      "+---------+--------------+-------------+-------------------------+\n",
      "|NULL     |NULL          |NULL         |2024-01-24 10:40:31.36331|\n",
      "|1        |John Doe      |New York     |2024-01-24 10:40:31.36331|\n",
      "|2        |Jane Smith    |Los Angeles  |2024-01-24 10:40:31.36331|\n",
      "|3        |Robert Johnson|Chicago      |2024-01-24 10:40:31.36331|\n",
      "|4        |Emily Davis   |San Francisco|2024-01-24 10:40:31.36331|\n",
      "+---------+--------------+-------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "420ebc9b-f923-43b2-832d-693dfc0be7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, BooleanType, ArrayType\n",
    "\n",
    "snippet_schema = StructType(fields = [StructField(\"channelId\", StringType(), True),\n",
    "                                      StructField(\"title\", StringType(),True),\n",
    "                                      StructField(\"assignable\", BooleanType(), True)\n",
    "                            \n",
    "])\n",
    "\n",
    "items_schema = StructType(fields = [StructField(\"kind\", StringType(), True),\n",
    "                                    StructField(\"etag\", StringType(), True),\n",
    "                                    StructField(\"id\", IntegerType(), True),\n",
    "                                    StructField(\"snippet\", snippet_schema)\n",
    "                                   ])\n",
    "\n",
    "df_schema = StructType(fields = [StructField(\"kind\", StringType(), True),\n",
    "                                 StructField(\"etag\", StringType(), True),\n",
    "                                 StructField(\"items\", ArrayType(items_schema)),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73b90eaf-d0e9-408a-9848-b87e103a7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nested json\n",
    "df = spark.read.schema(df_schema).json(\"C:/Users/bibhusha.ojha_genese/Desktop/SparkSQL/youtube-data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf22e996-2a67-4792-bcbf-c221ef63a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- kind: string (nullable = true)\n",
      " |-- etag: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- kind: string (nullable = true)\n",
      " |    |    |-- etag: string (nullable = true)\n",
      " |    |    |-- id: integer (nullable = true)\n",
      " |    |    |-- snippet: struct (nullable = true)\n",
      " |    |    |    |-- channelId: string (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- assignable: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() #nested schema json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f459768-9039-4b59-8299-9ab2891160a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|kind|etag|items|\n",
      "+----+----+-----+\n",
      "|NULL|NULL| NULL|\n",
      "|NULL|NULL| NULL|\n",
      "|NULL|NULL| NULL|\n",
      "|NULL|NULL| NULL|\n",
      "|NULL|NULL| NULL|\n",
      "+----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "#solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3647193b-da47-4bcb-8015-9410e2905423",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_schema = StructType ([ StructField(\"firstname\", StringType(), True),\n",
    "                           StructField(\"lastname\", StringType(), True),\n",
    "])\n",
    "\n",
    "nested_schema = StructType(fields= [ StructField(\"id\", IntegerType(), True),\n",
    "                                    StructField(\"name\", name_schema),\n",
    "                                    StructField(\"dob\", StringType(), True),\n",
    "                                    StructField(\"nationality\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fca1d0d6-f5b1-4b74-b4ef-51d34cc6dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.schema(nested_schema).json(\"C:/Users/bibhusha.ojha_genese/Desktop/SparkSQL/nested-json.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef4f6b1d-40bf-4e39-90dc-2f6ec710c8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7fd2970-9cf6-43e8-bfe2-268b40b43584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------+-----------+\n",
      "| id|              name|       dob|nationality|\n",
      "+---+------------------+----------+-----------+\n",
      "|  1|       {John, Doe}|1990-05-15|   American|\n",
      "|  2|     {Jane, Smith}|1985-12-10|   Canadian|\n",
      "|  3|{Michael, Johnson}|1995-08-22|    British|\n",
      "|  4|    {Emily, Brown}|1988-03-28| Australian|\n",
      "|  5|  {Robert, Miller}|1992-11-07|     German|\n",
      "+---+------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b427a48-21c0-4c61-8b83-163a58e824e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, current_timestamp, lit\n",
    "df_with_column = df.withColumn(\"name\", concat(col(\"name.firstname\"),lit(\" \"),col(\"name.lastname\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7853357-bdb0-43b6-b2d7-9536b0f3ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the names into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50d6c785-2277-483f-96ac-a4cdb90545af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----------+-----------+\n",
      "| id|           name|       dob|nationality|\n",
      "+---+---------------+----------+-----------+\n",
      "|  1|       John Doe|1990-05-15|   American|\n",
      "|  2|     Jane Smith|1985-12-10|   Canadian|\n",
      "|  3|Michael Johnson|1995-08-22|    British|\n",
      "|  4|    Emily Brown|1988-03-28| Australian|\n",
      "|  5|  Robert Miller|1992-11-07|     German|\n",
      "+---+---------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_column.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6079e00-deb8-4297-8d83-879ade9e8b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
